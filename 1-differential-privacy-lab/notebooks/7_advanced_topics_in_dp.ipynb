{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0adce05",
   "metadata": {},
   "source": [
    "# ðŸ“š Advanced Topics in Differential Privacy\n",
    "\n",
    "Built by **Stu** ðŸš€\n",
    "\n",
    "_Context: Understanding RDP, Moments Accountant, and DP-SGD_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08784dbf",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "We move beyond basic Differential Privacy into advanced mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d1791a",
   "metadata": {},
   "source": [
    "## Section 1: RÃ©nyi Differential Privacy (RDP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4496919",
   "metadata": {},
   "source": [
    "### Exercise 1: What is RÃ©nyi Divergence?\n",
    "\n",
    "Define RÃ©nyi divergence in your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "359839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "renyi_divergence_definition = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e7b4c",
   "metadata": {},
   "source": [
    "### Exercise 2: Why RDP over basic DP?\n",
    "\n",
    "Explain the advantages of RDP for composition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d8d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdp_advantages = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f71b6b",
   "metadata": {},
   "source": [
    "### Exercise 3: Single-Step Gaussian RDP Calculation\n",
    "\n",
    "Given Ïƒ (standard deviation) = 1.0, Î± (order) = 2, compute RDP value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e8f2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = 1.0\n",
    "alpha = 2\n",
    "rdp_value = alpha / (2 * sigma**2)\n",
    "rdp_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5691f2f",
   "metadata": {},
   "source": [
    "### Exercise 4: Build RDP Cumulative Tracker\n",
    "\n",
    "Write a function to sum RDP values over multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acae6a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_rdp(rdp_per_step, steps):\n",
    "    return rdp_per_step * steps\n",
    "\n",
    "accumulate_rdp(rdp_value, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655f2e51",
   "metadata": {},
   "source": [
    "### Exercise 5: Classical vs RDP Composition\n",
    "\n",
    "Briefly compare classical privacy loss vs RDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af327e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "classical_vs_rdp = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02d7815",
   "metadata": {},
   "source": [
    "### Exercise 6: Convert RDP to (Îµ, Î´)-DP Estimate\n",
    "\n",
    "Write formula connecting RDP to final (Îµ, Î´)-DP guarantee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f21372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdp_to_dp(rdp, alpha, delta):\n",
    "    return rdp + (np.log(1/delta)) / (alpha - 1)\n",
    "\n",
    "rdp_to_dp(rdp_value, alpha, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52356ad",
   "metadata": {},
   "source": [
    "## Section 2: RDP Privacy Accountant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f10766e",
   "metadata": {},
   "source": [
    "### Exercise 7: Build Simple Privacy Accountant\n",
    "\n",
    "Track total RDP loss over training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38491054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def privacy_accountant(sigma, steps, alpha=2):\n",
    "    rdp_per_step = alpha / (2 * sigma**2)\n",
    "    return accumulate_rdp(rdp_per_step, steps)\n",
    "\n",
    "privacy_accountant(1.0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471a2db",
   "metadata": {},
   "source": [
    "### Exercise 8: Plot RDP Growth Over Steps\n",
    "\n",
    "Plot cumulative RDP over 1000 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8c1249",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(0, 1001)\n",
    "rdps = accumulate_rdp(rdp_value, steps)\n",
    "\n",
    "plt.plot(steps, rdps)\n",
    "plt.xlabel('Training Steps')\n",
    "plt.ylabel('RDP')\n",
    "plt.title('RDP Accumulation Over Training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ea862c",
   "metadata": {},
   "source": [
    "### Exercise 9: Privacy Loss Interpretation\n",
    "\n",
    "Interpret what high RDP values mean for user privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d92ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_rdp_meaning = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f3d0d",
   "metadata": {},
   "source": [
    "## Section 3: DP-SGD (Differentially Private Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036e61b",
   "metadata": {},
   "source": [
    "### Exercise 10: Sketch How DP-SGD Works\n",
    "\n",
    "Describe how DP-SGD modifies standard SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ec8804",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_sgd_explanation = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89840d66",
   "metadata": {},
   "source": [
    "### Exercise 11: Add Gaussian Noise to Gradients\n",
    "\n",
    "Write a function that adds Gaussian noise to gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daac7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise_to_gradients(gradients, sigma):\n",
    "    noise = np.random.normal(0, sigma, size=gradients.shape)\n",
    "    return gradients + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa83782",
   "metadata": {},
   "source": [
    "### Exercise 12: Build a Toy MLP (PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e51cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ToyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ToyMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 16)\n",
    "        self.fc2 = nn.Linear(16, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = ToyMLP()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8911f7e",
   "metadata": {},
   "source": [
    "### Exercise 13: Minibatch Sampling\n",
    "\n",
    "Write code to sample minibatches from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ad732fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_minibatch(X, y, batch_size):\n",
    "    indices = np.random.choice(len(X), batch_size, replace=False)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd180d33",
   "metadata": {},
   "source": [
    "### Exercise 14: Apply Noise After Backward Pass\n",
    "\n",
    "Add Gaussian noise to gradients after `.backward()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61cce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise_to_model(model, sigma):\n",
    "    for param in model.parameters():\n",
    "        if param.grad is not None:\n",
    "            noise = torch.normal(0, sigma, size=param.grad.shape)\n",
    "            param.grad += noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4555ba1c",
   "metadata": {},
   "source": [
    "### Exercise 15: Train with Noisy Gradients\n",
    "\n",
    "Train the toy model with DP-SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b81c0f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode: this will be run in a real setup\n",
    "# for epoch in range(epochs):\n",
    "#     X_batch, y_batch = sample_minibatch(X_train, y_train, batch_size)\n",
    "#     optimizer.zero_grad()\n",
    "#     outputs = model(X_batch)\n",
    "#     loss = criterion(outputs, y_batch)\n",
    "#     loss.backward()\n",
    "#     apply_noise_to_model(model, sigma=1.0)\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af8212",
   "metadata": {},
   "source": [
    "### Exercise 16: Plot Privacy vs Accuracy\n",
    "\n",
    "Plot epsilon vs model accuracy over training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3c5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pseudocode (depends on training loop)\n",
    "# plt.plot(epsilons, accuracies)\n",
    "# plt.xlabel('Privacy Loss Îµ')\n",
    "# plt.ylabel('Model Accuracy')\n",
    "# plt.title('Privacy vs Accuracy')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
